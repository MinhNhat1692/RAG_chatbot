import os
from dotenv import load_dotenv
import openai
import faiss
import numpy as np
import mysql.connector
import pickle
import json
import re

# Load .env file
load_dotenv()

# Use environment variables
openai.api_key = os.getenv("OPENAI_API_KEY")

EMBEDDING_MODEL = 'text-embedding-3-small'

def connect_db():
    return mysql.connector.connect(
        host=os.getenv("DB_HOST"),
        user=os.getenv("DB_USER"),
        password=os.getenv("DB_PASSWORD"),
        database=os.getenv("DB_NAME")
    )

def embed_text(text):
    response = openai.embeddings.create(
        model=EMBEDDING_MODEL,
        input=text
    )
    return np.array(response.data[0].embedding, dtype=np.float32)

# ------------------- Store / Load from DB -------------------
def store_knowledge(content):
    embedding = embed_text(content)
    serialized = pickle.dumps(embedding)

    db = connect_db()
    cursor = db.cursor()

    # Check if already exists
    cursor.execute("SELECT id FROM knowledge WHERE content = %s", (content,))
    if cursor.fetchone():
        print(f"[Info] Already exists in DB: \"{content[:50]}...\"")
        cursor.close()
        db.close()
        return

    cursor.execute("INSERT INTO knowledge (content, embedding) VALUES (%s, %s)", (content, serialized))
    db.commit()
    cursor.close()
    db.close()
    print(f"[Saved] \"{content[:50]}...\"")

def load_all_embeddings():
    db = connect_db()
    cursor = db.cursor()
    cursor.execute("SELECT id, content, embedding FROM knowledge")
    rows = cursor.fetchall()
    cursor.close()
    db.close()

    results = []
    for row in rows:
        id, content, emb_blob = row
        embedding = pickle.loads(emb_blob)
        results.append((id, content, embedding))
    return results

def get_conversation_history(convo_id):
    db = connect_db()
    cursor = db.cursor()

    # Get linked knowledge content for this conversation
    cursor.execute("""
        SELECT k.content 
        FROM conversation_link cl
        JOIN knowledge k ON cl.knowledge_id = k.id
        WHERE cl.conversation_id = %s
        ORDER BY cl.id ASC
    """, (convo_id,))
    
    history = [row[0] for row in cursor.fetchall()]

    cursor.close()
    db.close()

    return history

expected_info = ["kÃ­ch thÆ°á»›c", "mÃ u sáº¯c", "sá»‘ bá»™", "sá»‘ Ä‘iá»‡n thoáº¡i", "Ä‘á»‹a chá»‰ giao hÃ ng"]

def detect_missing_info(convo_texts):
    joined_history = "\n".join(convo_texts)
    prompt = f"""
Báº¡n lÃ  má»™t trá»£ lÃ½ bÃ¡n hÃ ng. DÆ°á»›i Ä‘Ã¢y lÃ  lá»‹ch sá»­ cuá»™c trÃ² chuyá»‡n vá»›i khÃ¡ch hÃ ng.

Má»¥c tiÃªu lÃ  láº¥y Ä‘á»§ thÃ´ng tin sau, theo thá»© tá»±:
1. KÃ­ch thÆ°á»›c
2. MÃ u sáº¯c
3. Sá»‘ bá»™ (sá»‘ lÆ°á»£ng, sá»‘ cÃ¡i, thÆ°á»ng náº¿u khÃ¡ch chá»n 1 mÃ u thÃ¬ 1 cÃ¡i, 2 mÃ u lÃ  2 cÃ¡i ..)
4. Sá»‘ Ä‘iá»‡n thoáº¡i
5. Äá»‹a chá»‰ giao hÃ ng

HÃ£y phÃ¢n tÃ­ch Ä‘oáº¡n há»™i thoáº¡i vÃ  trÃ­ch xuáº¥t thÃ´ng tin náº¿u cÃ³. Náº¿u chÆ°a cÃ³, Ä‘á»ƒ giÃ¡ trá»‹ lÃ  null.

Tráº£ vá» káº¿t quáº£ dÆ°á»›i dáº¡ng JSON:
{{
  "kÃ­ch thÆ°á»›c": "60" | "70" | "80" | ... | null,
  "mÃ u sáº¯c": "tráº¯ng" | "Ä‘en" | ... | null,
  "sá»‘ bá»™": 2 | 3 | ... | null,
  "sá»‘ Ä‘iá»‡n thoáº¡i": "0123456789" | null,
  "Ä‘á»‹a chá»‰ giao hÃ ng": "Ä‘á»‹a chá»‰ Ä‘áº§y Ä‘á»§" | null
}}

Lá»‹ch sá»­ há»™i thoáº¡i:
{joined_history}
"""

    response = openai.chat.completions.create(
        model="gpt-4.1-nano",
        messages=[{"role": "user", "content": prompt}],
        temperature=0,
        max_tokens=1000,
    )

    result = response.choices[0].message.content.strip()

    try:
        return json.loads(result)
    except json.JSONDecodeError:
        print("âŒ Lá»—i parse JSON tá»« GPT:", result)
        return {}


# ------------------- RAG Class -------------------
class RAG:
    def __init__(self, dim=1536):
        self.index = faiss.IndexFlatL2(dim)
        self.texts = []

        # Load from DB
        entries = load_all_embeddings()
        if entries:
            vecs = [e[2] for e in entries]
            self.index.add(np.array(vecs))
            self.texts = [e[1] for e in entries]
            print(f"[Loaded] {len(self.texts)} entries from DB.")

    def add(self, text):
        if text in self.texts:
            print(f"[Skip] Already added to FAISS: \"{text[:50]}...\"")
            return

        store_knowledge(text)  # Will skip if already in DB
        vec = embed_text(text)
        self.index.add(np.array([vec]))
        self.texts.append(text)
        print(f"[Added] To FAISS: \"{text[:50]}...\"")

    def search(self, query, texts=None, k=5):
        if texts is None:
            texts = self.texts
            vecs = self.index
            return self._search_faiss(query, texts, vecs, k)
        else:
            # Combine provided texts with self.texts
            combined_texts = self.texts + texts
            vecs = [embed_text(t) for t in combined_texts]
            q_vec = embed_text(query)
            sims = [(t, np.linalg.norm(q_vec - v)) for t, v in zip(combined_texts, vecs)]
            sims.sort(key=lambda x: x[1])
            return sims[:k]

    
    def _search_faiss(self, query, texts, vecs, k):
        q_vec = embed_text(query)
        D, I = self.index.search(np.array([q_vec]), k)
        return [(texts[i], D[0][idx]) for idx, i in enumerate(I[0]) if i != -1]

    def get_conversation_knowledge(self, convo_id):
        db = connect_db()
        cursor = db.cursor()
        cursor.execute("""
            SELECT k.content 
            FROM conversation_link cl
            JOIN knowledge k ON cl.knowledge_id = k.id
            WHERE cl.conversation_id = %s
        """, (convo_id,))
        texts = [row[0] for row in cursor.fetchall()]
        cursor.close()
        db.close()
        return texts

    def store_and_link_query(self, convo_id, text, source='user'):
        db = connect_db()
        cursor = db.cursor()

        # Step 1: Check if knowledge already exists
        cursor.execute("SELECT id FROM knowledge WHERE content = %s", (text,))
        row = cursor.fetchone()

        if row:
            knowledge_id = row[0]
            print(f"[Info] Already in knowledge DB")
        else:
            # Insert new knowledge
            embedding = embed_text(text)
            serialized = pickle.dumps(embedding)
            cursor.execute(
                "INSERT INTO knowledge (content, embedding) VALUES (%s, %s)",
                (text, serialized)
            )
            knowledge_id = cursor.lastrowid
            self.index.add(np.array([embedding]))
            self.texts.append(text)
            print(f"[Saved + FAISS] \"{text[:50]}...\"")

        # Step 2: Link to conversation with 'from' column
        cursor.execute(
            "SELECT 1 FROM conversation_link WHERE conversation_id = %s AND knowledge_id = %s",
            (convo_id, knowledge_id)
        )
        if not cursor.fetchone():
            cursor.execute(
                "INSERT INTO conversation_link (conversation_id, knowledge_id, from_source) VALUES (%s, %s, %s)",
                (convo_id, knowledge_id, source)
            )
            print(f"[Linked] query to conversation_id={convo_id} from={source}")

        db.commit()
        cursor.close()
        db.close()
        return knowledge_id

def answer_question(question, contexts, next_missing=None, info_status=None):
    context_block = "\n".join(contexts)

    # Build known info summary
    known_info = []
    info_dict = {}
    if info_status:
        for key, value in info_status.items():
            if value:  # giÃ¡ trá»‹ khÃ¡c rá»—ng
                known_info.append(key)
                info_dict[key] = value  # âœ… láº¥y giÃ¡ trá»‹ trá»±c tiáº¿p tá»« info_status

    known_info_str = ", ".join(known_info) if known_info else "ChÆ°a cÃ³ thÃ´ng tin nÃ o"

    # âœ… Náº¿u Ä‘Ã£ Ä‘áº§y Ä‘á»§ thÃ´ng tin â†’ xÃ¡c Ä‘á»‹nh intent trÆ°á»›c
    if next_missing is None:
        # Gá»­i prompt Ä‘á»ƒ phÃ¢n loáº¡i intent
        intent_prompt = f"""
Báº¡n lÃ  má»™t trá»£ lÃ½ bÃ¡n hÃ ng. PhÃ¢n loáº¡i cÃ¢u cá»§a khÃ¡ch vÃ o 1 trong 3 nhÃ³m sau (chá»‰ tráº£ vá» Ä‘Ãºng sá»‘):
1. KhÃ¡ch Ä‘ang cung cáº¥p thÃªm thÃ´ng tin Ä‘Æ¡n hÃ ng (sá»‘ Ä‘iá»‡n thoáº¡i vÃ  Ä‘á»‹a chá»‰)
2. KhÃ¡ch xÃ¡c nháº­n muá»‘n Ä‘áº·t hÃ ng
3. CÃ¢u nÃ³i khÃ´ng liÃªn quan hoáº·c chÆ°a rÃµ Ã½ Ä‘á»‹nh

CÃ¢u cá»§a khÃ¡ch: "{question}"

Chá»‰ tráº£ lá»i báº±ng 1, 2 hoáº·c 3.
"""
        intent_response = openai.chat.completions.create(
            model="gpt-4.1-nano",
            messages=[{"role": "user", "content": intent_prompt}],
            max_tokens=10,
            temperature=0
        )
        intent = intent_response.choices[0].message.content.strip()

        if intent == "1":
            # TrÆ°á»ng há»£p khÃ¡ch Ä‘ang cung cáº¥p thÃªm thÃ´ng tin â†’ tráº£ láº¡i nhÆ° cÅ©
            so_bo = info_dict.get("sá»‘ bá»™", 1)
            try:
                so_bo = int(so_bo)
            except ValueError:
                so_bo = 1

            if so_bo > 1:
                tong_tien = so_bo * 170000
            else:
                tong_tien = so_bo * 175000

            thong_tin_don_hang = "\n".join([
                f"- {key.capitalize()}: {info_dict.get(key, '...')}"
                for key in ["kÃ­ch thÆ°á»›c", "mÃ u sáº¯c", "sá»‘ bá»™", "sá»‘ Ä‘iá»‡n thoáº¡i", "Ä‘á»‹a chá»‰ giao hÃ ng"]
            ])

            return (
                f"Dáº¡ em Ä‘Ã£ ghi nháº­n Ä‘áº§y Ä‘á»§ thÃ´ng tin Ä‘Æ¡n hÃ ng cá»§a mÃ¬nh áº¡:\n"
                f"{thong_tin_don_hang}\n"
                f"ğŸ‘‰ Tá»•ng tiá»n: {tong_tien:,} VNÄ\n\n"
                f"Dáº¡ em gá»­i khoáº£ng 3-4 ngÃ y chá»‹ nháº­n Ä‘Æ°á»£c, chá»‹ nháº­n thanh toÃ¡n giÃºp em {tong_tien:,} VNÄ vÃ  phÃ­ ship áº¡"
            )

        elif intent == "2":
            return "Dáº¡ em cáº£m Æ¡n chá»‹ nhiá»u áº¡ ğŸ’– Em sáº½ tiáº¿n hÃ nh lÃªn Ä‘Æ¡n ngay cho mÃ¬nh nhÃ©!"

        else:
            return "Chá»‹ chá» em chÃºt áº¡ ğŸ«¶"

    # ğŸ§  TrÆ°á»ng há»£p thiáº¿u thÃ´ng tin â†’ tiáº¿p tá»¥c há»i
    base_prompt = f"""Báº¡n lÃ  má»™t trá»£ lÃ½ bÃ¡n hÃ ng chuyÃªn nghiá»‡p. Tráº£ lá»i dá»±a trÃªn thÃ´ng tin bÃªn dÆ°á»›i, sau Ä‘Ã³ há»i thÃªm thÃ´ng tin tiáº¿p theo.

ThÃ´ng tin Ä‘Ã£ biáº¿t: {known_info_str}
ThÃ´ng tin cáº§n biáº¿t tiáº¿p theo: {next_missing}

ThÃ´ng tin thÃªm:
{context_block}

CÃ¢u cá»§a khÃ¡ch: {question}
Tráº£ lá»i:"""

    response = openai.chat.completions.create(
        model="gpt-4.1-nano",
        messages=[{"role": "user", "content": base_prompt}],
        max_tokens=1000,
        temperature=0.1
    )
    print("prompt:", base_prompt)
    answer = response.choices[0].message.content.strip()
    return answer

if __name__ == '__main__':
    rag = RAG()

    query = "quáº§n Ã¡o cá»¡ 70 lÃ  cho Ä‘á»‘i tÆ°á»£ng nÃ o"
    results = rag.search(query)
    top_texts = [text for text, _ in results]

    answer = answer_question(query, top_texts)
    print("\nAnswer:\n", answer)
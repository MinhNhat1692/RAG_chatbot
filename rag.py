import os
from dotenv import load_dotenv
import openai
import faiss
import numpy as np
import mysql.connector
import pickle
import json
import re

# Load .env file
load_dotenv()

# Use environment variables
openai.api_key = os.getenv("OPENAI_API_KEY")

EMBEDDING_MODEL = 'text-embedding-3-small'

def connect_db():
    return mysql.connector.connect(
        host=os.getenv("DB_HOST"),
        user=os.getenv("DB_USER"),
        password=os.getenv("DB_PASSWORD"),
        database=os.getenv("DB_NAME")
    )

def embed_text(text):
    response = openai.embeddings.create(
        model=EMBEDDING_MODEL,
        input=text
    )
    return np.array(response.data[0].embedding, dtype=np.float32)

# ------------------- Store / Load from DB -------------------
def store_knowledge(content):
    embedding = embed_text(content)
    serialized = pickle.dumps(embedding)

    db = connect_db()
    cursor = db.cursor()

    # Check if already exists
    cursor.execute("SELECT id FROM knowledge WHERE content = %s", (content,))
    if cursor.fetchone():
        print(f"[Info] Already exists in DB: \"{content[:50]}...\"")
        cursor.close()
        db.close()
        return

    cursor.execute("INSERT INTO knowledge (content, embedding) VALUES (%s, %s)", (content, serialized))
    db.commit()
    cursor.close()
    db.close()
    print(f"[Saved] \"{content[:50]}...\"")

def load_all_embeddings():
    db = connect_db()
    cursor = db.cursor()
    cursor.execute("SELECT id, content, embedding FROM knowledge")
    rows = cursor.fetchall()
    cursor.close()
    db.close()

    results = []
    for row in rows:
        id, content, emb_blob = row
        embedding = pickle.loads(emb_blob)
        results.append((id, content, embedding))
    return results

def get_conversation_history(convo_id):
    db = connect_db()
    cursor = db.cursor()

    # Get linked knowledge content for this conversation
    cursor.execute("""
        SELECT k.content 
        FROM conversation_link cl
        JOIN knowledge k ON cl.knowledge_id = k.id
        WHERE cl.conversation_id = %s
        ORDER BY cl.id ASC
    """, (convo_id,))
    
    history = [row[0] for row in cursor.fetchall()]

    cursor.close()
    db.close()

    return history

expected_info = ["kÃ­ch thÆ°á»›c", "mÃ u sáº¯c", "sá»‘ bá»™", "sá»‘ Ä‘iá»‡n thoáº¡i", "Ä‘á»‹a chá»‰ giao hÃ ng"]

def detect_missing_info(convo_texts):
    joined_history = "\n".join(convo_texts)
    prompt = f"""
Báº¡n lÃ  má»™t trá»£ lÃ½ bÃ¡n hÃ ng. DÆ°á»›i Ä‘Ã¢y lÃ  lá»‹ch sá»­ cuá»™c trÃ² chuyá»‡n vá»›i khÃ¡ch hÃ ng.

KhÃ¡ch hÃ ng cÃ³ thá»ƒ Ä‘áº·t **nhiá»u Ä‘Æ¡n hÃ ng**, má»—i Ä‘Æ¡n gá»“m:
- KÃ­ch thÆ°á»›c
- MÃ u sáº¯c
- Sá»‘ bá»™

NgoÃ i ra cáº§n thu tháº­p:
- Sá»‘ Ä‘iá»‡n thoáº¡i
- Äá»‹a chá»‰ giao hÃ ng

HÃ£y phÃ¢n tÃ­ch Ä‘oáº¡n há»™i thoáº¡i vÃ  trÃ­ch xuáº¥t cÃ¡c thÃ´ng tin trÃªn.
Náº¿u thiáº¿u thÃ´ng tin nÃ o, Ä‘á»ƒ giÃ¡ trá»‹ lÃ  null.

Tráº£ vá» káº¿t quáº£ dÆ°á»›i dáº¡ng JSON nhÆ° sau:

{{
  "Ä‘Æ¡n hÃ ng": [
    {{
      "kÃ­ch thÆ°á»›c": "60" | "70" | "80" | null,
      "mÃ u sáº¯c": "tráº¯ng" | "Ä‘en" | null,
      "sá»‘ bá»™": 1 | 2 | 3 | null
    }},
    ...
  ],
  "sá»‘ Ä‘iá»‡n thoáº¡i": "0123456789" | null,
  "Ä‘á»‹a chá»‰ giao hÃ ng": "Ä‘á»‹a chá»‰ Ä‘áº§y Ä‘á»§" | null
}}

Lá»‹ch sá»­ há»™i thoáº¡i:
{joined_history}
"""

    response = openai.chat.completions.create(
        model="gpt-4.1-nano",
        messages=[{"role": "user", "content": prompt}],
        temperature=0,
        max_tokens=1000,
    )

    result = response.choices[0].message.content.strip()

    try:
        return json.loads(result)
    except json.JSONDecodeError:
        print("âŒ Lá»—i parse JSON:", result)
        return {}


# ------------------- RAG Class -------------------
class RAG:
    def __init__(self, dim=1536):
        self.index = faiss.IndexFlatL2(dim)
        self.texts = []

        # Load from DB
        #entries = load_all_embeddings()
        #if entries:
        #    vecs = [e[2] for e in entries]
        #    self.index.add(np.array(vecs))
        #    self.texts = [e[1] for e in entries]
        #    print(f"[Loaded] {len(self.texts)} entries from DB.")

    def add(self, text):
        if text in self.texts:
            print(f"[Skip] Already added to FAISS: \"{text[:50]}...\"")
            return

        store_knowledge(text)  # Will skip if already in DB
        vec = embed_text(text)
        self.index.add(np.array([vec]))
        self.texts.append(text)
        print(f"[Added] To FAISS: \"{text[:50]}...\"")

    def search(self, query, texts=None, k=5):
        if texts is None:
            texts = self.texts
            vecs = self.index
            return self._search_faiss(query, texts, vecs, k)
        else:
            # Combine provided texts with self.texts
            combined_texts = self.texts + texts
            vecs = [embed_text(t) for t in combined_texts]
            q_vec = embed_text(query)
            sims = [(t, np.linalg.norm(q_vec - v)) for t, v in zip(combined_texts, vecs)]
            sims.sort(key=lambda x: x[1])
            return sims[:k]

    
    def _search_faiss(self, query, texts, vecs, k):
        q_vec = embed_text(query)
        D, I = self.index.search(np.array([q_vec]), k)
        return [(texts[i], D[0][idx]) for idx, i in enumerate(I[0]) if i != -1]

    def get_conversation_knowledge(self, convo_id):
        db = connect_db()
        cursor = db.cursor()
        cursor.execute("""
            SELECT k.content 
            FROM conversation_link cl
            JOIN knowledge k ON cl.knowledge_id = k.id
            WHERE cl.conversation_id = %s
        """, (convo_id,))
        texts = [row[0] for row in cursor.fetchall()]
        cursor.close()
        db.close()
        return texts

    def store_and_link_query(self, convo_id, text, source='user'):
        db = connect_db()
        cursor = db.cursor()

        # Step 1: Check if knowledge already exists
        cursor.execute("SELECT id FROM knowledge WHERE content = %s", (text,))
        row = cursor.fetchone()

        if row:
            knowledge_id = row[0]
            print(f"[Info] Already in knowledge DB")
        else:
            # Insert new knowledge
            embedding = embed_text(text)
            serialized = pickle.dumps(embedding)
            cursor.execute(
                "INSERT INTO knowledge (content, embedding) VALUES (%s, %s)",
                (text, serialized)
            )
            knowledge_id = cursor.lastrowid
            self.index.add(np.array([embedding]))
            self.texts.append(text)
            print(f"[Saved + FAISS] \"{text[:50]}...\"")

        # Step 2: Link to conversation with 'from' column
        cursor.execute(
            "SELECT 1 FROM conversation_link WHERE conversation_id = %s AND knowledge_id = %s",
            (convo_id, knowledge_id)
        )
        if not cursor.fetchone():
            cursor.execute(
                "INSERT INTO conversation_link (conversation_id, knowledge_id, from_source) VALUES (%s, %s, %s)",
                (convo_id, knowledge_id, source)
            )
            print(f"[Linked] query to conversation_id={convo_id} from={source}")

        db.commit()
        cursor.close()
        db.close()
        return knowledge_id

def answer_question(question, contexts, next_missing=None, info_status=None):
    context_block = "\n".join(contexts)

    if next_missing is None:
        # Gá»­i prompt Ä‘á»ƒ phÃ¢n loáº¡i intent
        intent_prompt = f"""
Báº¡n lÃ  má»™t trá»£ lÃ½ bÃ¡n hÃ ng. PhÃ¢n loáº¡i cÃ¢u cá»§a khÃ¡ch vÃ o 1 trong 3 nhÃ³m sau (chá»‰ tráº£ vá» Ä‘Ãºng sá»‘):
1. KhÃ¡ch Ä‘ang cung cáº¥p thÃªm thÃ´ng tin Ä‘Æ¡n hÃ ng (sá»‘ Ä‘iá»‡n thoáº¡i vÃ  Ä‘á»‹a chá»‰)
2. KhÃ¡ch xÃ¡c nháº­n muá»‘n Ä‘áº·t hÃ ng
3. CÃ¢u nÃ³i khÃ´ng liÃªn quan hoáº·c chÆ°a rÃµ Ã½ Ä‘á»‹nh

CÃ¢u cá»§a khÃ¡ch: "{question}"

Chá»‰ tráº£ lá»i báº±ng 1, 2 hoáº·c 3.
"""
        intent_response = openai.chat.completions.create(
            model="gpt-4.1-nano",
            messages=[{"role": "user", "content": intent_prompt}],
            max_tokens=10,
            temperature=0
        )
        intent = intent_response.choices[0].message.content.strip()

        don_hang_list = info_status.get('Ä‘Æ¡n hÃ ng', [])

        def get_first_valid_value(key):
            for dh in don_hang_list:
                val = dh.get(key)
                if val not in (None, "", "chÆ°a rÃµ"):
                    return val
            return "chÆ°a rÃµ"

        # Tá»•ng sá»‘ bá»™ = tá»•ng cá»™ng 'sá»‘ bá»™' trong cÃ¡c Ä‘Æ¡n hÃ ng, bá» qua None hoáº·c giÃ¡ trá»‹ khÃ´ng há»£p lá»‡
        total_so_bo = 0
        for dh in don_hang_list:
            try:
                so_bo = int(dh.get("sá»‘ bá»™", 0) or 0)
                total_so_bo += so_bo
            except (ValueError, TypeError):
                continue
        if total_so_bo == 0:
            total_so_bo = 1  # máº·c Ä‘á»‹nh 1 náº¿u khÃ´ng cÃ³ sá»‘ bá»™ há»£p lá»‡

        order_info = {
            "kÃ­ch thÆ°á»›c": get_first_valid_value("kÃ­ch thÆ°á»›c"),
            "mÃ u sáº¯c": get_first_valid_value("mÃ u sáº¯c"),
            "sá»‘ bá»™": total_so_bo,
            "sá»‘ Ä‘iá»‡n thoáº¡i": info_status.get("sá»‘ Ä‘iá»‡n thoáº¡i") or "chÆ°a rÃµ",
            "Ä‘á»‹a chá»‰ giao hÃ ng": info_status.get("Ä‘á»‹a chá»‰ giao hÃ ng") or "chÆ°a rÃµ",
        }

        # TÃ­nh tá»•ng tiá»n theo sá»‘ bá»™
        tong_tien = total_so_bo * (170000 if total_so_bo > 1 else 175000)

        if intent == "1":
            answer = (
                f"Dáº¡ em Ä‘Ã£ ghi nháº­n Ä‘áº§y Ä‘á»§ thÃ´ng tin Ä‘Æ¡n hÃ ng cá»§a mÃ¬nh áº¡:\n" +
                "\n".join([f"- {k.capitalize()}: {v}" for k, v in order_info.items()]) +
                f"\nğŸ‘‰ Tá»•ng tiá»n: {tong_tien:,} VNÄ\n\n"
                f"Dáº¡ em gá»­i khoáº£ng 3-4 ngÃ y chá»‹ nháº­n Ä‘Æ°á»£c, chá»‹ nháº­n thanh toÃ¡n giÃºp em {tong_tien:,} VNÄ vÃ  phÃ­ ship áº¡"
            )
            return {
                "order_info": order_info,
                "answer": answer,
                "question": "Chá»‹ cÃ³ cáº§n em há»— trá»£ gÃ¬ thÃªm khÃ´ng áº¡?"
            }

        elif intent == "2":
            return {
                "order_info": order_info,
                "answer": "Dáº¡ em cáº£m Æ¡n chá»‹ nhiá»u áº¡ ğŸ’– Em sáº½ tiáº¿n hÃ nh lÃªn Ä‘Æ¡n ngay cho mÃ¬nh nhÃ©!",
                "question": "Chá»‹ cÃ³ cáº§n Ä‘á»•i gÃ¬ thÃªm khÃ´ng áº¡, vÃ­ dá»¥ sá»‘ bá»™ hay mÃ u sáº¯c?"
            }

        else:
            return {
                "order_info": order_info,
                "answer": "Chá»‹ chá» em chÃºt áº¡ ğŸ«¶",
                "question": "KhÃ´ng biáº¿t chá»‹ muá»‘n cung cáº¥p thÃªm thÃ´ng tin hay xÃ¡c nháº­n Ä‘áº·t hÃ ng áº¡?"
            }

    # ğŸ§  TrÆ°á»ng há»£p thiáº¿u thÃ´ng tin â†’ tiáº¿p tá»¥c há»i
    base_prompt = f"""
Báº¡n lÃ  má»™t trá»£ lÃ½ bÃ¡n hÃ ng chuyÃªn nghiá»‡p. HÃ£y thá»±c hiá»‡n 3 viá»‡c:
1. Tráº£ lá»i khÃ¡ch má»™t cÃ¡ch thÃ¢n thiá»‡n.
2. Náº¿u thiáº¿u thÃ´ng tin, hÃ£y há»i tiáº¿p khÃ¡ch vá» thÃ´ng tin cÃ²n thiáº¿u.
3. Tráº£ vá» káº¿t quáº£ dÆ°á»›i dáº¡ng JSON vá»›i 2 trÆ°á»ng: answer_only (chá»‰ cÃ³ cÃ¢u tráº£ lá»i hoáº·c cÃ¢u há»i xÃ¡c nháº­n), question_ask_next (cÃ¢u há»i tiáº¿p theo cáº§n há»i Ä‘á»ƒ biáº¿t thÃ´ng tin cáº§n biáº¿t tiáº¿p theo).

Tráº£ lá»i dá»±a trÃªn thÃ´ng tin Ä‘Æ¡n hÃ ng á»Ÿ dáº¡ng JSON dÆ°á»›i Ä‘Ã¢y vÃ  cÃ¢u há»i cá»§a khÃ¡ch hÃ ng.

ThÃ´ng tin Ä‘Æ¡n hÃ ng:
{json.dumps(info_status, ensure_ascii=False, indent=2)}
ThÃ´ng tin cáº§n biáº¿t tiáº¿p theo: {next_missing}

ThÃ´ng tin thÃªm:
{context_block}

CÃ¢u cá»§a khÃ¡ch: {question}
Káº¿t quáº£ tráº£ vá» (JSON):""".strip()

    response = openai.chat.completions.create(
        model="gpt-4.1-nano",
        messages=[{"role": "user", "content": base_prompt}],
        max_tokens=500,
        temperature=0.1
    )

    print("ğŸ” prompt:", base_prompt)

    raw_output = response.choices[0].message.content.strip()
    print("ğŸ” raw model output:", raw_output)

    try:
        result = json.loads(raw_output)
    except Exception:
        # fallback: try to parse manually if model doesn't return valid JSON
        result = False

    return result

if __name__ == '__main__':
    rag = RAG()

    query = "quáº§n Ã¡o cá»¡ 70 lÃ  cho Ä‘á»‘i tÆ°á»£ng nÃ o"
    results = rag.search(query)
    top_texts = [text for text, _ in results]

    answer = answer_question(query, top_texts)
    print("\nAnswer:\n", answer)